#  A Scikit-Learn based Indexer for contructing an inverted index in pickle format-search indexing:â€“ 
# Required: TF-IDF score/weight representation, Cosine similarity
# Solution ==> This code implements an inverted index using Scikit-Learn for constructing a search indexing system with TF-IDF score representation and cosine similarity.
# 1. **Initialization**: Initializes an empty inverted index.
# 2. **Add Document**: Calculates TF-IDF weights for each document and adds them to the index.
# 3. **Save Index**: Saves the constructed index to a pickle file.
# 4. **Load Index**: Loads the previously saved index from the pickle file.
# 5. **Query Index**: Calculates TF-IDF weights for the query, computes cosine similarity scores with each document, and returns the top K documents based on similarity.
# 6. **Reading HTML Files**: Reads HTML files generated by a web crawler.
# 7. **Adding Documents to Index**: Adds extracted text from HTML files to the inverted index.
# 8. **Saving Index to File**: Saves the constructed index to a pickle file.
# 9. **Loading Index from File**: Loads the saved index from the pickle file.
# 10. **Querying Index**: Performs a query on the loaded index with a given query text.


import os
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class InvertedIndex:
    def __init__(self):
        self.index = {}

    def add_document(self, doc_id, doc_text):
        # Calculate the TF-IDF weights for the document
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform([doc_text])

        # Add the TF-IDF weights to the index
        for term, weight in zip(vectorizer.get_feature_names_out(), tfidf_matrix.toarray()[0]):
            if term not in self.index:
                self.index[term] = {}
            self.index[term][doc_id] = weight

    def save(self, filename):
        print("Saving index to file...")
        with open(filename, "wb") as f:
            pickle.dump(self.index, f)
        print("Index saved successfully.")

    def load(self, filename):
        print("Loading index from file...")
        with open(filename, "rb") as f:
            self.index = pickle.load(f)
        print("Index loaded successfully.")

    def query(self, query_text):
        print("Querying index...")
        # Calculate the TF-IDF weights for the query
        vectorizer = TfidfVectorizer()
        query_vector = vectorizer.fit_transform([query_text]).toarray()[0]

        # Calculate cosine similarity between the query and each document in the index
        doc_scores = {}
        for term, query_weight in zip(vectorizer.get_feature_names_out(), query_vector):
            if term in self.index:
                for doc_id, doc_weights in self.index[term].items():
                    doc_scores[doc_id] = doc_scores.get(doc_id, 0) + query_weight * doc_weights

        # Return the top K documents based on cosine similarity
        print("Query completed.")
        return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:10]

# Read HTML files generated by the web crawler
html_files_dir = 'crawled_html'
html_files = os.listdir(html_files_dir)

# Initialize inverted index
index = InvertedIndex()

# Extract text from HTML files and add them to the index
for doc_id, file in enumerate(html_files, start=1):
    with open(os.path.join(html_files_dir, file), 'r', encoding='utf-8') as f:
        html_content = f.read()
        # Extract text from HTML content (you need to implement this part)
        # For demonstration, let's assume we directly use HTML content as text
        text = html_content
        index.add_document(doc_id, text)

# Save the index to a file
index_file = "index.pickle"
index.save(index_file)

# Load the index from a file
index = InvertedIndex()
index.load(index_file)

# Query the index
query_text = "Your query text here"
print("Querying the index with text:", query_text)
results = index.query(query_text)

# Print the results along with TF-IDF weights
print("Top results:")
for doc_id, score in results:
    print(f"Document ID: {doc_id} | Cosine Similarity Score: {score}")
    print("TF-IDF Weights:")
    for term, weights in index.index.items():
        if doc_id in weights:
            print(f"\t{term}: {weights[doc_id]}")
